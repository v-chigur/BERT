{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "engaged-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "old_data = pd.read_csv(\"cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blank-satellite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>витино кингисепп дорога идеальный</td>\n",
       "      <td>Дорога с идеальным или близким к идеальному по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>качество покрытие отличный постоянно ремонт ул...</td>\n",
       "      <td>Дорога с идеальным или близким к идеальному по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>трасса зеркало видимо давно обновлять инф</td>\n",
       "      <td>Дорога с идеальным или близким к идеальному по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>чистить асфальт ровный выбоина</td>\n",
       "      <td>Дорога с идеальным или близким к идеальному по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>отличный дорога</td>\n",
       "      <td>Дорога с идеальным или близким к идеальному по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11848</th>\n",
       "      <td>9956</td>\n",
       "      <td>м-38 омск казахстан дорога самый хороший асфал...</td>\n",
       "      <td>Дорога со значительными разрушениями дорожного...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>9957</td>\n",
       "      <td>хребтовый усть-кут плохой дорога время путь 5 30</td>\n",
       "      <td>Дорожное покрытие полностью разрушено, постоян...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11850</th>\n",
       "      <td>9958</td>\n",
       "      <td>4</td>\n",
       "      <td>Дорога с относительно ровным дорожным полотном</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11851</th>\n",
       "      <td>9959</td>\n",
       "      <td>трасса тотьма -никольск слово негатив результа...</td>\n",
       "      <td>Дорожное покрытие полностью разрушено, постоян...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11852</th>\n",
       "      <td>9960</td>\n",
       "      <td>делиться информация пожалуйста трасса уфа сара...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11853 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               text  \\\n",
       "0               0                  витино кингисепп дорога идеальный   \n",
       "1               1  качество покрытие отличный постоянно ремонт ул...   \n",
       "2               2          трасса зеркало видимо давно обновлять инф   \n",
       "3               3                     чистить асфальт ровный выбоина   \n",
       "4               4                                    отличный дорога   \n",
       "...           ...                                                ...   \n",
       "11848        9956  м-38 омск казахстан дорога самый хороший асфал...   \n",
       "11849        9957   хребтовый усть-кут плохой дорога время путь 5 30   \n",
       "11850        9958                                                  4   \n",
       "11851        9959  трасса тотьма -никольск слово негатив результа...   \n",
       "11852        9960  делиться информация пожалуйста трасса уфа сара...   \n",
       "\n",
       "                                                   label  \n",
       "0      Дорога с идеальным или близким к идеальному по...  \n",
       "1      Дорога с идеальным или близким к идеальному по...  \n",
       "2      Дорога с идеальным или близким к идеальному по...  \n",
       "3      Дорога с идеальным или близким к идеальному по...  \n",
       "4      Дорога с идеальным или близким к идеальному по...  \n",
       "...                                                  ...  \n",
       "11848  Дорога со значительными разрушениями дорожного...  \n",
       "11849  Дорожное покрытие полностью разрушено, постоян...  \n",
       "11850     Дорога с относительно ровным дорожным полотном  \n",
       "11851  Дорожное покрытие полностью разрушено, постоян...  \n",
       "11852                                                NaN  \n",
       "\n",
       "[11853 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "shaped-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = old_data['label'].unique()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decimal-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = old_data.loc[old_data.label.isin(labels)]\n",
    "data = data[data['text'].apply(type) == str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tribal-transition",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Заменяем названия классов на 0 или 1\n",
    "data['label'].replace(labels[0], 1, inplace=True)\n",
    "data['label'].replace(labels[1:], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inclusive-integration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_data = data['text'].tolist()\n",
    "y_data = data['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "announced-durham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>витино кингисепп дорога идеальный</td>\n",
       "      <td>Дорога с идеальным или близким к идеальному по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>качество покрытие отличный постоянно ремонт ул...</td>\n",
       "      <td>Дорога с идеальным или близким к идеальному по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>трасса зеркало видимо давно обновлять инф</td>\n",
       "      <td>Дорога с идеальным или близким к идеальному по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>чистить асфальт ровный выбоина</td>\n",
       "      <td>Дорога с идеальным или близким к идеальному по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>отличный дорога</td>\n",
       "      <td>Дорога с идеальным или близким к идеальному по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11848</th>\n",
       "      <td>9956</td>\n",
       "      <td>м-38 омск казахстан дорога самый хороший асфал...</td>\n",
       "      <td>Дорога со значительными разрушениями дорожного...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>9957</td>\n",
       "      <td>хребтовый усть-кут плохой дорога время путь 5 30</td>\n",
       "      <td>Дорожное покрытие полностью разрушено, постоян...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11850</th>\n",
       "      <td>9958</td>\n",
       "      <td>4</td>\n",
       "      <td>Дорога с относительно ровным дорожным полотном</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11851</th>\n",
       "      <td>9959</td>\n",
       "      <td>трасса тотьма -никольск слово негатив результа...</td>\n",
       "      <td>Дорожное покрытие полностью разрушено, постоян...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11852</th>\n",
       "      <td>9960</td>\n",
       "      <td>делиться информация пожалуйста трасса уфа сара...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11838 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               text  \\\n",
       "0               0                  витино кингисепп дорога идеальный   \n",
       "1               1  качество покрытие отличный постоянно ремонт ул...   \n",
       "2               2          трасса зеркало видимо давно обновлять инф   \n",
       "3               3                     чистить асфальт ровный выбоина   \n",
       "4               4                                    отличный дорога   \n",
       "...           ...                                                ...   \n",
       "11848        9956  м-38 омск казахстан дорога самый хороший асфал...   \n",
       "11849        9957   хребтовый усть-кут плохой дорога время путь 5 30   \n",
       "11850        9958                                                  4   \n",
       "11851        9959  трасса тотьма -никольск слово негатив результа...   \n",
       "11852        9960  делиться информация пожалуйста трасса уфа сара...   \n",
       "\n",
       "                                                   label  \n",
       "0      Дорога с идеальным или близким к идеальному по...  \n",
       "1      Дорога с идеальным или близким к идеальному по...  \n",
       "2      Дорога с идеальным или близким к идеальному по...  \n",
       "3      Дорога с идеальным или близким к идеальному по...  \n",
       "4      Дорога с идеальным или близким к идеальному по...  \n",
       "...                                                  ...  \n",
       "11848  Дорога со значительными разрушениями дорожного...  \n",
       "11849  Дорожное покрытие полностью разрушено, постоян...  \n",
       "11850     Дорога с относительно ровным дорожным полотном  \n",
       "11851  Дорожное покрытие полностью разрушено, постоян...  \n",
       "11852                                                NaN  \n",
       "\n",
       "[11838 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_data[old_data['text'].apply(type) == str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spanish-phoenix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923495067445138"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "lens = [len(x.split()) for x in X_data]\n",
    "len_counter = Counter(lens)\n",
    "plt.bar(len_counter.keys(), len_counter.values())\n",
    "len([l for l in lens if l < 100]) / len(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "furnished-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение всей выборки на обучающую (80%), валидационную (10%) и тестовую (10%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "contemporary-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# использование токенайзера DeepPavlov\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\", \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "increasing-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.batch_encode_plus(X_train, add_special_tokens=True, \n",
    "                                      padding='max_length', truncation=True, max_length=100, \n",
    "                                      return_tensors='pt', return_attention_mask=True)\n",
    "\n",
    "X_val = tokenizer.batch_encode_plus(X_val, add_special_tokens=True, \n",
    "                                    padding='max_length', truncation=True, max_length=100, \n",
    "                                    return_tensors='pt', return_attention_mask=True)\n",
    "\n",
    "X_test = tokenizer.batch_encode_plus(X_test, add_special_tokens=True, \n",
    "                                     padding='max_length', truncation=True, max_length=100, \n",
    "                                     return_tensors='pt', return_attention_mask=True)\n",
    "\n",
    "y_train, y_val, y_test = (torch.LongTensor(y) for y in [y_train, y_val, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caring-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# деление множества на батчи\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_data = TensorDataset(X_train['input_ids'], X_train['attention_mask'], y_train)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(X_val['input_ids'], X_val['attention_mask'], y_val)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(X_test['input_ids'], X_test['attention_mask'])\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "diverse-citizen",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"DeepPavlov/rubert-base-cased\", \n",
    "                                                      num_labels = 2, \n",
    "                                                      output_attentions = False,\n",
    "                                                      output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "impressive-butter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "chief-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "n_epochs = 8\n",
    "n_steps = len(train_dataloader) * n_epochs\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "welsh-yeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1 epoch\n",
      "Mean loss:  0.37251975951000477\n",
      "Training epoch took: 0:02:55\n",
      "\n",
      "Validation:\n",
      "Precision 0.70, recall 0.71, F1 0.71\n",
      "Validation took: 0:00:05\n",
      "\n",
      "Training 2 epoch\n",
      "Mean loss:  0.2635732809685066\n",
      "Training epoch took: 0:03:08\n",
      "\n",
      "Validation:\n",
      "Precision 0.74, recall 0.76, F1 0.75\n",
      "Validation took: 0:00:05\n",
      "\n",
      "Training 3 epoch\n",
      "Mean loss:  0.18805821026043903\n",
      "Training epoch took: 0:03:07\n",
      "\n",
      "Validation:\n",
      "Precision 0.80, recall 0.70, F1 0.75\n",
      "Validation took: 0:00:05\n",
      "\n",
      "Training 4 epoch\n",
      "Mean loss:  0.1300658223203288\n",
      "Training epoch took: 0:03:11\n",
      "\n",
      "Validation:\n",
      "Precision 0.74, recall 0.79, F1 0.76\n",
      "Validation took: 0:00:05\n",
      "\n",
      "Training 5 epoch\n",
      "Mean loss:  0.1003251843404126\n",
      "Training epoch took: 0:03:01\n",
      "\n",
      "Validation:\n",
      "Precision 0.85, recall 0.71, F1 0.77\n",
      "Validation took: 0:00:05\n",
      "\n",
      "Training 6 epoch\n",
      "Mean loss:  0.06059102387770905\n",
      "Training epoch took: 0:02:49\n",
      "\n",
      "Validation:\n",
      "Precision 0.83, recall 0.71, F1 0.77\n",
      "Validation took: 0:00:05\n",
      "\n",
      "Training 7 epoch\n",
      "Mean loss:  0.0400829852545321\n",
      "Training epoch took: 0:02:41\n",
      "\n",
      "Validation:\n",
      "Precision 0.83, recall 0.75, F1 0.79\n",
      "Validation took: 0:00:05\n",
      "\n",
      "Training 8 epoch\n",
      "Mean loss:  0.03125894928978329\n",
      "Training epoch took: 0:02:40\n",
      "\n",
      "Validation:\n",
      "Precision 0.83, recall 0.72, F1 0.77\n",
      "Validation took: 0:00:05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datetime import timedelta\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "seed = 42\n",
    "\n",
    "random.seed = (seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "model.cuda()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Training {} epoch\".format(epoch + 1))\n",
    "    start = time.time()\n",
    "    mean_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_attention_masks = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        outputs = model(b_input_ids, attention_mask=b_attention_masks, labels = b_labels)\n",
    "        loss = outputs[0]\n",
    "        \n",
    "        mean_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    mean_loss = mean_loss / len(train_dataloader)\n",
    "    \n",
    "    train_losses.append(mean_loss)\n",
    "    print(\"Mean loss: \" , mean_loss)\n",
    "    print(\"Training epoch took:\" , timedelta(seconds=int(time.time() - start)))\n",
    "    \n",
    "    print()\n",
    "    print(\"Validation:\")\n",
    "    model.eval()\n",
    "    \n",
    "    start = time.time()\n",
    "    predictions = torch.Tensor().to(dtype=torch.int8)\n",
    "    val_loss = 0\n",
    "    \n",
    "    for batch in val_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_attention_masks = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, attention_mask=b_attention_masks, labels=b_labels,\n",
    "                            output_hidden_states=False, output_attentions=False, return_dict=True)\n",
    "            val_loss += outputs[0].item()\n",
    "        \n",
    "        predictions = torch.cat((predictions, outputs.logits.cpu().argmax(axis=1)))\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    val_losses.append(val_loss / len(val_dataloader))\n",
    "    print(\"Precision {:4.2f}, recall {:4.2f}, F1 {:4.2f}\".format(*[a(y_val, predictions)\n",
    "                                                                   for a in (precision_score, recall_score, f1_score)]))\n",
    "    print(\"Validation took: {:}\".format(timedelta(seconds = int(time.time() - start))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "animated-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95       809\n",
      "           1       0.84      0.65      0.74       185\n",
      "\n",
      "    accuracy                           0.91       994\n",
      "   macro avg       0.88      0.81      0.84       994\n",
      "weighted avg       0.91      0.91      0.91       994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing:\")\n",
    "model.eval()\n",
    "\n",
    "t0 = time.time()\n",
    "predictions = torch.Tensor().to(dtype=torch.int8)\n",
    "\n",
    "for batch in test_dataloader:\n",
    "\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_attention_masks = batch[1].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, attention_mask=b_attention_masks, output_hidden_states=False, output_attentions=False, return_dict=True)\n",
    "\n",
    "    predictions = torch.cat((predictions, outputs.logits.cpu().argmax(axis=1)))\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "overall-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model_bert_74_8.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-boring",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
